<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Excerpt</title>
</head>
<body>
    <h2>Excerpt</h2>
    <p>Although critical for economic planning, disaster preparedness, and policy-making, subseasonal-to-seasonal (S2S) prediction is lagging behind the more established field of short/medium-range weather, or long-range climate predictions.</p><p>For instance, many natural hazards tend to manifest in the S2S scale, including the slow-onset of droughts that lead to wildfire, heavy precipitations that lead to flooding, and persistent weather anomalies that lead to extremes.</p><p>So far, current approaches to weather and climate prediction are heavily reliant on physics-based models in the form of Numerical Weather Prediction (NWP).</p><p>Many NWPs are based on the discretization of governing equations that describe thermodynamics, fluid flows, etc.</p><p>However, these models are expensive to run especially in high-resolution setting.</p><p>Furthermore, their relative inaccessibility to non-experts is a major roadblock to the broader community.</p><p>As a result, there is a growing interest to apply data-driven models to emulate NWPs, as they tend to have faster inference speed, are less resource-hungry, and more accessible.</p><p>Nevertheless, many data-driven benchmarks have so far been focused on the short (1–5 days), medium (5–15 days), and long (years–decades) forecasting ranges.</p><p>In this work, we include S2S as a more challenging task that requires different emulation strategies.</p><p>It is doubly sensitive to initial conditions (IC) as in the case for short/medium-range weather, and boundary conditions (BC) as in the case for long-range climate.</p><p>We propose ChaosBench to bridge these gaps.</p><p>It is comprised of variables beyond the typical surface-atmospheric ERA5 to also include ocean, ice, and land reanalysis products that span over 45 years to allow for full Earth system emulation that respects boundary processes.</p><p>We also provide 44-day ahead physics-based control (deterministic) and perturbed (ensemble) forecasts from four national weather agencies over the last 8 years as baselines.</p><p>In addition, we introduce physics-based and incorporate probabilistic, in addition to deterministic metrics, for a more physically-consistent ensemble that accounts for butterfly effect.</p><p>As far as we know, ChaosBench is one of the first to systematically evaluate several state-of-the-art data-driven models including ViT/ClimaX, PanguWeather, GraphCast, and FourCastNetV2 on S2S predictability.</p><p>We demonstrate that existing physics-based and data-driven models are indistinguishable from unskilled climatology as the forecasting range approaches the S2S timescale.</p><p>The high spectral divergence observed in many state-of-the-art models suggests the lost of predictive accuracy of multi-scale structures.</p><p>This leads to significant blurring and a tendency towards smoother predictions.</p><p>Performing comparably worse than climatology renders them operationally unusable.</p><p>This highlights the urgent need for a robust and unified data-driven S2S intercomparison project.</p><p>Many existing benchmarks are built for short/medium-range weather (up to 15 days), and long-term climate (annual to decadal scale).</p><p>These problems tend to be easier due to the lack of combined sensitivities to IC and BC.</p><p>Many S2S benchmarks tend to focus on regional forecasts.</p><p>ChaosBench has the most extensive overlapping temporal coverage yet, extending to 45+ years of inputs covering multiple reanalysis products beyond ERA5.</p><p>Having a large set of physics-based forecasts as baselines is key to reducing bias and diversifying the target goal-posts.</p><p>ChaosBench also places weights on expanding the diversity of physics-based models.</p><p>ChaosBench introduces physics-based metrics that can be used for comparison and integrated into ML pipeline.</p><p>ERA5 Reanalysis provides a comprehensive record of the global atmosphere combining physics and observations for correction.</p><p>ORAS5 provides an extensive record of sea-ice variables that incorporate multiple depth levels.</p><p>LRA5 provides a detailed record of variables governing global terrestrial processes with specific corrections tailored for land surface applications.</p><p>Forecasts are generated from 2016 to present.</p><p>The UK Meteorological Office uses the Global Seasonal Forecast System Version 6 (GloSea6) to generate daily ensemble/control forecasts for 60-day lead time.</p><p>The National Centers for Environmental Prediction uses the Climate Forecast System 2 (CFSv2) model to generate daily ensemble/control forecast for 45-day lead time.</p><p>The China Meteorological Administration uses the Beijing Climate Center (BCC) model to generate ensemble/control forecasts at 3-day interval for 60-day lead time.</p><p>The European Centre for Medium-Range Weather Forecasts uses the CY41R1 version of the IFS to generate ensemble/control forecasts twice weekly for 46-day lead time.</p><p>We provide an assortment of metrics, which we divide into deterministic, probabilistic, and several proposed physics-based criteria.</p><p>RMSE is useful to penalize outliers.</p><p>Bias assists us to identify misspecification and systematic errors present in the model.</p><p>ACC measures the correlation between predicted and observed anomalies.</p><p>MS-SSIM compares structural similarity between forecast and ground-truth label across scales.</p><p>We propose two physics-based metrics that measure the deviation or difference between the power spectra of prediction and target.</p><p>Spectral Divergence (SpecDiv) computes the expectation of the log ratio between target and prediction spectra.</p><p>Spectral Residual (SpecRes) computes the root of the expected squared residual.</p><p>CRPS evaluates the accuracy of the ensemble distribution against the target.</p><p>CRPSS evaluates the skill of probabilistic forecast relative to climatology variability.</p><p>Spread quantifies the uncertainty in ensemble forecasts.</p><p>Spread/Skill Ratio balances the ensemble spread with the forecast skill.</p><p>We find that deterministic ML models perform worse than climatology on S2S timescale.</p><p>These forecasts exhibit significantly higher spectral divergence.</p><p>This leads to blurring artifacts.</p><p>The pervasive lack of predictive skill underscores the notoriously difficult challenge of S2S forecasting.</p><p>The performance of ensembles across physics-based models improves relative to their deterministic counterparts.</p><p>Higher ensemble size appears to improve skillfulness.</p><p>Controlling for stability is key to extend the predictability range of weather emulators.</p><p>Models trained directly have better performance than those used autoregressively.</p><p>Models that explicitly incorporate physical knowledge have better performance across metrics.</p><p>ECMWF high-resolution ensemble still has the best performance in terms of CRPSS.</p><p>Its predictability range is around 15–20 days ahead before skill collapses to climatology.</p><p>The resurgence of data-driven models is rapidly transforming the field.</p><p>We present ChaosBench, a challenging benchmark to extend the predictability range of weather emulators into the S2S timescale.</p><p>We perform extensive benchmarking on state-of-the-art data-driven and physics-based models.</p><p>Skillfulness can be extended by ensemble forecasting, controlling for exponential error growth, and incorporating physical knowledge.</p>
    <h2>Original Abstract</h2> 
    <p>Subseasonal-to-seasonal (S2S) forecasting remains a major challenge in climate and weather prediction, despite its critical importance for disaster preparedness, economic planning, and policy-making. Traditional Numerical Weather Prediction (NWP) models are computationally intensive and inaccessible to non-experts, while most data-driven methods have focused on shorter or longer time horizons, leaving S2S underexplored. To address this gap, we introduce ChaosBench, a comprehensive benchmark designed to evaluate data-driven and physics-based models on the S2S scale. ChaosBench integrates over 45 years of global Earth system reanalysis data—spanning atmospheric, oceanic, ice, and land variables—and includes 44-day ensemble/control forecasts from four national weather agencies. We propose a suite of deterministic, probabilistic, and novel physics-based metrics to evaluate forecasting skill and structural fidelity. Benchmarking results reveal that state-of-the-art data-driven models degrade rapidly on the S2S horizon, often performing worse than climatology due to spectral divergence and blurring. In contrast, ensemble-based and physically-informed models show improved robustness. Our findings highlight the need for a unified and physically-consistent S2S evaluation framework and establish ChaosBench as a foundational resource for advancing the frontier of data-driven weather emulation.</p>
</body>
</html>
