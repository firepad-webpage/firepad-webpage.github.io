<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Excerpt</title>
</head>
<body>
    <h2>Excerpt</h2>
    <p>The increasing workload diversity in modern data use cases has led to the proliferation of specialized data management systems, each targeted to a somewhat narrow class of workloads.</p> <p>Based on the “one size does not fit all” engine specialization tenet, hundreds of database system offerings were developed in the last few decades and are today available in the industry.</p> <p>While workloads, requirements, and environmental trends have dramatically evolved since the first databases were developed, our software development practices have not; data management systems continue to be, by and large, developed and distributed as vertically integrated monoliths.</p> <p>While modern specialized data systems may seem distinct at first, at the core, they are all composed of a similar set of logical components.</p> <p>However, this fragmentation and consequent lack of reuse across systems has slowed us down.</p> <p>It has forced developers to reinvent the wheel, duplicating work and hurting our ability to quickly adapt systems as requirements evolve.</p> <p>Our development model still leads to siloed systems, high maintenance costs, and wasted engineering cycles, suggesting we can be more efficient as an engineering community.</p> <p>More importantly, the byproducts of this fragmentation — incompatible SQL and non-SQL APIs, disparate functionality, distinct function packages, and inconsistent semantics across the board — impact the productivity of end users who are commonly required to interact with multiple distinct data systems to finish a particular task, each with their own quirks.</p> <p>We believe it is time for a paradigm shift.</p> <p>We envision that by decomposing data management systems into a more modular stack of reusable components, the development of new engines can be streamlined, while reducing maintenance costs and ultimately providing a more consistent user experience.</p> <p>By relying on a modular stack that reuses execution engine and language frontend, data systems code could provide a more consistent experience and semantics to users, from transactional to analytic systems, from stream processing to machine learning workloads.</p> <p>Given these trends, we foresee that composability is soon to cause another major disruption to how data management systems are designed.</p> <p>We foresee that monolithic systems will become obsolete, and give space to a new composable era for data management.</p> <p>We highlight the importance of composability in data management systems and argue that now is the right moment for a paradigm shift.</p> <p>We summarize previous work that describe individual projects in the composability space, their significance so far, and the investments required going forward.</p> <p>We extend the state-of-the-art by presenting a novel reference composable architecture, and discussing the parts of this stack that have received less attention but are key to component composability and reusability, highlighting open questions and areas that require additional research.</p> <p>Decomposing software complexity into smaller subsets of relatively independent components is a well-known software design technique.</p> <p>We believe that increasing the degree of composability in data management systems, by developing and adopting reusable components, provides the benefits discussed below.</p> <p>By reducing the duplication of work, more engineers could work on fewer systems and components.</p> <p>For large organizations, having fewer codebases reduces operational burden, and allows engineering teams to focus on new features, optimizations, and other enhancements.</p> <p>Data system diversity disincentivizes hardware vendors from investing in hardware support for data processing.</p> <p>By reusing the same components, from language to execution, users can expect consistent semantics across data systems, in addition to a more even set of available features.</p> <p>Libraries and frameworks are complicated and take time to learn.</p> <p>Developers are often passionate about writing their own code, and commonly find reading documentation and reviewing someone else’s code to be a tedious process.</p> <p>It is also common for developers to believe that a quick prototype containing a subset of functionality decreases the time-to-market for their products.</p> <p>In many cases, a component that provides the required functionality exists, but is written in the wrong programming language, has too many dependencies, is too hard to use, or is distributed under an incompatible license.</p> <p>Developers are usually not compelled to write reusable components because there are few incentives to do so.</p> <p>We believe the path forward is to focus on the following principles: (a) define and agree on a standard set of logical components across data management systems, (b) define stable (yet extensible) APIs for communication between these components, (c) provide canonical implementations for these components and APIs which are efficient and consistent, and (d) provide extensibility APIs in every layer of the stack to allow developers to implement specialized behavior.</p> <p>The new modular data stack emerging in the open source community provides a stronger separation between language and execution, in such a way that the execution is language-independent, and takes a well-defined and system-agnostic intermediate representation (IR) as input.</p> <p>This model is general enough, and allows every existing data management system to be mapped to it, from OLTP to OLAP systems, stream processing, log analytics, ML preprocessing and more.</p> <p>These components are predominantly consistent across specialized data management systems, and the areas where they specialize/diverge are the exception rather than the norm.</p> <p>Despite the current fragmentation, language frontend is the most straightforward layer in the stack to be made composable due to its simple API: translate user input into an IR.</p> <p>We believe that, more generally, language will meet execution through a unified IR.</p> <p>We believe language frontend modularization to also pave the way for language unification, or supporting a single unified SQL dialect, and a single unified dataframe dialect across data management systems.</p> <p>Intermediate representation (IR) is a term commonly used in the field of compilers to describe any structured representation of a program that carries enough information to allow it to be accurately executed.</p> <p>Substrait is a recent pioneering effort at providing a unified and cross-language IR specification.</p> <p>However, a few challenges arise as we work towards making this unification practical in real-life data systems.</p> <p>IRs will need to become part of the system’s external API.</p> <p>IRs are not yet descriptive enough to ensure runtime semantic equivalence.</p> <p>The set of functions available today in different systems are fully disparate.</p> <p>We believe the path forward to be, in the future, to bypass dialect and function packages incompatibilities through language and execution unification.</p> <p>Query optimization is a very diverse and well-studied field.</p> <p>While the majority of the industry query optimizers are tailored to the target database system, there has been a significant body of work related to building extensible and composable query optimizers.</p> <p>Execution is the layer responsible for taking a query fragment as input (represented by an IR), and executing it leveraging the local resources provided by the execution runtime.</p> <p>Execution is a highly fragmented domain, posing challenges to large organizations which are required to individually maintain dozens of siloed and specialized codebases due to user workload diversity.</p> <p>Velox is the first large-scale open source project aimed at providing a unified execution engine for data management systems.</p> <p>Velox demonstrates that it is possible not just to componentize execution, but also to unify it across stacks.</p> <p>The execution runtime provides the environment needed by the execution engine to perform the computation.</p> <p>Although only a few of these systems have become truly widely used, there is currently no standardization to the level of abstraction that strikes the best balance between ease of programming and tight control of execution.</p> <p>We believe one principle should hold true: runtimes should not be coupled with data management systems, and preferably be interchangeable through a standard API.</p> <p>We encourage developers to consider the described logical stack, and ask themselves: which parts of this stack am I planning to specialize?</p> <p>We believe composable is the future of data management, and hope more individuals and organizations will join us in this effort.</p>
    <h2>Original Abstract</h2> 
    <p>The requirement for specialization in data management systems has evolved faster than our software development practices. After decades of organic growth, this situation has created a siloed landscape composed of hundreds of products developed and maintained as monoliths, with limited reuse between systems. This fragmentation has resulted in developers often reinventing the wheel, increased maintenance costs, and slowed down innovation. It has also affected the end users, who are often required to learn the idiosyncrasies of dozens of incompatible SQL and non-SQL API dialects, and settle for systems with incomplete functionality and inconsistent semantics. In this vision paper, considering the recent popularity of open source projects aimed at standardizing different aspects of the data stack, we advocate for a paradigm shift in how data management systems are designed. We believe that by decomposing these into a modular stack of reusable components, development can be streamlined while creating a more consistent experience for users. Towards that goal, we describe the state-of-the-art, principal open source technologies, and highlight open questions and areas where additional research is needed. We hope this work will foster collaboration, motivate further research, and promote a more composable future for data management.</p>
</body>
</html>
