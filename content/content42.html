<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Excerpt</title>
</head>
<body>
    <h2>Excerpt</h2>
    <p>Sparse matrix-matrix multiplication (SpMM) is a computational process where two sparse matrices are multiplied.</p><p>SpMM is a cornerstone in scientific simulations, linear algebra, graph analytics, and the rapidly evolving fields of deep learning.</p><p>Its crucial role in efficiently processing large-scale data structures and complex algorithms makes the effective acceleration of SpMM not just a computational challenge, but a key enabler in advancing researches and applications in these diverse and impactful domains.</p><p>The processing efficiency of SpMM is heavily influenced by the characteristics of the input sparse matrices.</p><p>The high proportion of zero elements in these matrices leads to challenges such as low utilization of computational and memory resources.</p><p>These irregular sparse patterns, coupled with unpredictable memory access patterns, present significant obstacles for conventional cache-based computing architectures.</p><p>As a result, SpMM often becomes a performance bottleneck, particularly in an era where processing large datasets is increasingly crucial.</p><p>Given the critical role of SpMM in various computational domains, developing specialized accelerators to enhance SpMM performance is important.</p><p>Existing SpMM accelerators predominantly utilize fixed execution flows, such as inner-product (InP), outer-product (OutP), or row-by-row (ROW), each tailored to optimize either input or output data reuse.</p><p>However, the efficiency of each execution flow is determined by sparse patterns, resulting in inconsistent performance across different sparse matrices.</p><p>This variability in performance due to differing sparse patterns underscores the need for SpMM execution flow that can dynamically adapt to optimize performance across a range of matrix structures.</p><p>Additionally, the existing SpMM accelerators exhibit limited capabilities in exploiting the inherent parallelism in SpMM, leading to several inefficiencies.</p><p>These inefficiencies impede the effective utilization of hardware resources and limit the overall performance of SpMM operations.</p><p>This underscores the need for designs that better align execution flows with the architecture, enhance fine-grained parallelism, and mitigate the synchronization overhead.</p><p>Furthermore, cache performance is crucial for the efficiency of SpMM accelerators, but is often overlooked.</p><p>Conventional cache replacement policies used in SpMM accelerators aim to reduce the number of cache misses but overlook the importance of concurrency.</p><p>Moreover, the design of caches in current accelerators does not incorporate non-blocking features.</p><p>As a result, a single cache miss causes delays in subsequent accesses, thereby exacerbating performance bottlenecks.</p><p>In this paper, we introduce ACES, an innovative accelerator for SpMM, specifically designed to dynamically adapt its execution flow to accommodate varying sparsity patterns, optimize parallel execution, and implement locality-concurrency co-optimizations for on-chip cache.</p><p>ACES has the following unique features.</p><p>ACES is equipped with an adaptive execution flow that intelligently adjusts to varying sparsity patterns of input matrices.</p><p>This adaptability is achieved through a spectrum of condensing degrees, implemented with minimal overhead and without altering the original encoding formats of the matrices.</p><p>ACES considers the reuse of input data and the synchronization needed for merging partial output results from each execution flow.</p><p>ACES employs PureFiber, a concurrency-aware cache replacement policy, to optimize cache management.</p><p>ACES incorporates a non-blocking buffer to manage cache miss accesses, ensuring that cache misses do not significantly disrupt subsequent accesses.</p><p>The hardware architecture of ACES is specifically designed to complement its adaptive execution flow and cache optimizations.</p><p>ACES not only consistently provides optimal performance across all workloads, with average speedups of 25.5× over SIGMA, 8.9× over SpArch, and 2.1× over SPADA, but also achieves this with the lowest area cost.</p><p>While conventional execution flows in SpMM provide distinct characteristics to matrix multiplication, there is no universally optimal solution.</p><p>The complexity of handling highly irregular sparsity patterns, coupled with the demands of parallel computing, underscores the need for innovative, adaptive execution flows.</p><p>SIGMA is an InP-based SpMM accelerator that enhances index intersection efficiency through a bitmap format.</p><p>SpArch adopts an OutP execution flow and proposes an aggressively condensed matrix representation for matrix A.</p><p>SPADA inherits ROW and introduces a window-based adaptive (WA) execution flow.</p><p>WA introduces a collective dependency among the multipliers.</p><p>ACES differentiates itself with an adaptive execution flow that balances data reuse and parallelism.</p><p>ACES emphasizes the co-optimizations of locality and concurrency in on-chip cache design and management.</p><p>The key components of ACES consist of a condensing adaptor, multiple PEs, two schedulers, and a global cache integrated with a non-blocking buffer.</p><p>ACES incorporates a condensation adapter that dynamically tunes the condensed matrix representation for matrix A.</p><p>ACES employs parallel computing, utilizing MPEs and APEs to support its adaptive execution flow.</p><p>A synchronization scheduler is designed to mitigate synchronization conflicts between APEs.</p><p>The global cache in ACES is a critical component, designed to efficiently manage both matrix B rows and matrix C partial output rows.</p><p>The PureFiber cache replacement policy is employed to manage cache lines effectively by considering both data locality and concurrency.</p><p>The integration of a NB buffer in the global cache supports the PureFiber policy and enhances performance by facilitating non-blocking accesses.</p><p>ACES introduces a mechanism offering a spectrum of condensing degrees to ensure an optimized execution flow tailored to each workload.</p><p>We first partition the entire matrix into bands.</p><p>For large bands, consisting of at least 256 rows, we identify the optimal condensing degree through the sampling phase.</p><p>For small bands, we apply moderate condensing by default.</p><p>Each MPE in ACES is specifically designed for executing scalar-vector multiplications.</p><p>ACES adopts a distinctive one-to-one pairing of MPEs with APEs.</p><p>Each APE handles the merging of newly produced partial output fibers with corresponding partial output fibers stored in the global cache.</p><p>In instances where there is no partial fiber in the global cache that can be merged, the APE writes the partial fiber into the cache directly.</p><p>The independent and concurrent processing by the APEs, in collaboration with the synchronization scheduler, enhances system parallelism.</p><p>After completing all scalar-vector multiplications, every APE in the system participates in the final merging stage.</p><p>ACES employs a merging scheduler to optimize this final merging process.</p><p>ACES utilizes the synchronization scheduler to efficiently assign fibers to APEs.</p><p>The synchronization scheduler coordinates with SQs and APEs to minimize stalls.</p><p>ACES adapts the Huffman tree to orchestrate the merging process for each row of the output matrix.</p><p>In the practical implementation of ACES, the Huffman tree is constructed using a priority queue.</p><p>The global cache in ACES stores fibers of matrix B and partial output fibers of matrix C.</p><p>We define pure fiber as a scenario where cache lines of a fiber are accessed concurrently without any cache misses.</p><p>We have developed PureFiber, a concurrency-aware cache replacement policy designed to prioritize achieving more pure fibers.</p><p>PureFiber integrates data locality and concurrency considerations for each cache line when making eviction decisions.</p><p>PureFiber optimizes cache management, focusing on increasing the number of pure fibers.</p><p>By prioritizing the eviction of higher-density fibers, PureFiber improves the overall pipeline efficiency in ACES.</p><p>ACES integrates an NB buffer with the global cache, creating an efficient non-blocking cache system.</p><p>The non-blocking cache ensures that cache misses do not stall subsequent cache accesses.</p><p>By allowing the cache to handle other requests during miss processing concurrently, the non-blocking design in ACES significantly reduces memory stall cycles.</p><p>ACES consistently outperforms all state-of-the-art accelerators across every workload.</p><p>On average, ACES achieves significant performance gains of 25.5×, 8.9×, and 2.1× over SIGMA, SpArch, and SPADA, respectively.</p><p>ACES incurs the lowest off-chip memory traffic compared to recent SpMM accelerators.</p><p>ACES consistently maintains PE utilization rates above 90.0% in 15 of the 18 evaluated workloads.</p><p>ACES achieves reduced area overhead while improving performance relative to accelerators with larger caches.</p><p>ACES supports an adaptive execution flow, adept at efficiently processing matrices with a wide range of sparse patterns.</p><p>It also integrates co-optimizations of data locality and concurrency within its global cache.</p><p>The hardware architecture of ACES is meticulously tailored to complement its adaptive execution capabilities.</p><p>Our comprehensive evaluations indicate that ACES consistently outperforms current state-of-the-art SpMM accelerators.</p>
    <h2>Original Abstract</h2> 
    <p>Sparse matrix-matrix multiplication (SpMM) is a fundamental operation in scientific computing and machine learning but remains a significant performance bottleneck due to the irregular sparsity patterns and poor cache utilization of sparse matrices. Existing accelerators rely on fixed execution flows, which are inefficient across varying sparsity structures and limit hardware utilization. This paper introduces ACES, a novel SpMM accelerator designed to dynamically adapt execution flows, optimize parallelism, and co-optimize data locality and concurrency for on-chip caches. ACES features an adaptive execution engine that intelligently selects execution strategies based on condensing degrees without modifying matrix formats. It incorporates PureFiber, a concurrency-aware cache replacement policy, and a non-blocking (NB) cache buffer to minimize access stalls. The architecture includes MPE-APE pairings, specialized schedulers, and Huffman tree-based merging to optimize throughput and synchronization. ACES consistently achieves superior performance, with average speedups of 25.5×, 8.9×, and 2.1× over SIGMA, SpArch, and SPADA, respectively, while maintaining over 90% processing element utilization in most workloads and reducing memory traffic and area overhead. These results demonstrate ACES as a high-performance, low-overhead, and adaptable solution to the longstanding inefficiencies of SpMM, offering substantial improvements in scalability and execution efficiency across diverse sparse workloads.</p>
</body>
</html>
