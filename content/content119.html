<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Excerpt</title>
</head>
<body>
    <h2>Excerpt</h2>
    <p>Serverless computing, as a new programming paradigm, has revolutionized how applications utilize cloud resources.</p>

<p>Various application domains, such as web services, online video processing, data analytics, scientific computing, and machine learning have embraced serverless computing model as this model simplifies how users deploy applications.</p>

<p>Serverless functions are latency-sensitive due to their short execution time—often in the range of seconds—leaving limited time for platforms to prepare a container, which takes over hundreds of milliseconds, severely inflating function response time, known as the notorious cold-start problem.</p>

<p>Serverless workloads are highly volatile, bursty, and hard-to-predict—recent research indicates that over 50% of functions on Microsoft Azure Function witness significantly varying invocation patterns.</p>

<p>The full-container caching has been widely applied as an effective solution addressing the burstiness in serverless computing.</p>

<p>Any mispredictions may lead to frequent cold-starts and vast memory waste.</p>

<p>Partial container caching increases the number of containers in memory, thus raising the hit rate of partially initialized containers.</p>

<p>Container sharing decreases the number of containers in memory due to their increased size but generalizes a container to be hit by different functions, raising the hit rate of the “over-packed” containers.</p>

<p>Both partial caching and container sharing solutions fail to strike a fundamental balance between cold-start mitigation and memory wasting.</p>

<p>We argue that partial container caching and sharing must be synergized to mitigate cold-starts with minimal memory waste.</p>

<p>RainbowCake enables layer-wise container caching and sharing by carefully exploiting different layers’ generalities: Lower-level container layers are lighter and can be shared by more functions. Higher-level layers save more start-up latency but are heavier and more specialized.</p>

<p>RainbowCake leverages invocations’ historical information to customize pre-warm and keep-alive strategies tailored to every function.</p>

<p>RainbowCake is designed to proactively pre-warm and keep-alive containers with fine-grained layer-wise caching decisions.</p>

<p>RainbowCake should enable function invocations to reuse and share containers with different layers.</p>

<p>RainbowCake should effectively mitigate cold-starts and maintain stable resource wasting when dealing with such burstiness and potential mispredictions.</p>

<p>RainbowCake should be able to effectively mitigate cold-starts of high concurrent invocations without introducing non-negligible overhead.</p>

<p>RainbowCake has two key components: the History Recorder and the Container Pool.</p>

<p>The History Recorder keeps observing invocation request arrivals and captures the invocation patterns by fitting sharing-aware distribution models with the collected invocation arrival records.</p>

<p>The Container Pool maintains containers of different layers and executes event-driven pre-warming and keep-alive operations according to the estimation of upcoming invocations.</p>

<p>RainbowCake enables idle containers partial keep-alive ability for safe and cross-function reuse.</p>

<p>We keep A’s User container alive for a while, then peel off the User layer of A, which downgrades to a Lang container.</p>

<p>Function B invocation can now reuse the Lang container since they have the same language runtime.</p>

<p>B invocation reuses the Lang container by installing its own User layer inside it, which can be considered as a partial warm-start that saves the startup time of installing Lang and Bare layers.</p>

<p>We peel off the User and Lang layers of B’s container during keep-alive, and C invocation can still reuse the Bare container of B with a partial warm-start to reduce startup latency.</p>

<p>A Bare container has only initialized the infrastructural environment and utilities for containers.</p>

<p>A Lang container has initialized a container with a language runtime based on the Bare container.</p>

<p>A User container, also known as a full-size container, has initialized user library/codebase based on the Lang container.</p>

<p>With a joint design of partial container caching and sharing, RainbowCake can achieve both a low function end-to-end latency and minimal memory cost.</p>

<p>RainbowCake carefully makes pre-warm & keep-alive decisions on caching proportions of containers to different layers at runtime with cross-function sharing awareness.</p>

<p>We leverage invocation history to model the sharing-aware arrival distributions of hits on each container type.</p>

<p>We fit the invocation distribution of function f using a sliding window on the latest n invocations.</p>

<p>RainbowCake enforces TTL-based pre-warming and keep-alive strategies when provisioning fine-grained containers layer-wise.</p>

<p>We propose an event-driven heuristic algorithm to dynamically adjust the length of pre-warming and keep-alive TTLs in real-time.</p>

<p>Upon the latest invocation arrival, RainbowCake’s container pool queries the function history to estimate the IAT.</p>

<p>Pre-warmed containers proceed to the keep-alive period immediately after startup, which can further downgrade and be reused by other invocations.</p>

<p>Every idle container needs to uninstall three layers sequentially in a keep-alive period: User, Lang, and Bare.</p>

<p>We ensure Lang and Bare containers are isolated from any user-related contents by removing them before sharing the container with other functions.</p>

<p>RainbowCake guarantees that a User container’s user remnants are completely wiped out before moving to Lang and Bare.</p>

<p>We implement RainbowCake in Apache OpenWhisk, an open-source, distributed serverless platform that executes functions using Docker containers.</p>

<p>RainbowCake is implemented with 8K lines of Scala for OpenWhisk modifications and 2K lines of Python for user client that runs experiments.</p>

<p>RainbowCake can configure three important system parameters: knob parameter α that balances the initialization cost and memory waste cost, window size n that keeps historical information of recent invocations, and the quantile p that represents the confidence for estimating invocation IATs.</p>

<p>RainbowCake achieves significantly less memory wasting than five baselines when the IAT CV increases.</p>

<p>RainbowCake shows significantly less total startup latency when the memory budget is limited.</p>

<p>RainbowCake’s pre-warming and keep-alive decisions incur negligible operational overhead compared to the original decision space.</p>

<p>Experimental results showed that RainbowCake reduces 68% startup latency and 77% container memory waste compared to existing solutions.</p>
<h2>Original Abstract</h2> 
<p>Serverless computing has grown rapidly as a new cloud computing paradigm that promises ease-of-management, cost-efficiency, and auto-scaling by shipping functions via self-contained virtualized containers. Unfortunately, serverless computing suffers from severe cold-start problems—starting containers incurs non-trivial latency. Full container caching is widely applied to mitigate cold-starts, yet has recently been outperformed by two lines of research: partial container caching and container sharing. However, either partial container caching or container sharing techniques exhibit their drawbacks. Partial container caching effectively deals with burstiness while leaving cold-start mitigation halfway; container sharing reduces cold-starts by enabling containers to serve multiple functions while suffering from excessive memory waste due to over-packed containers. </p> <p>This paper proposes RainbowCake, a layer-wise container pre-warming and keep-alive technique that effectively mitigates cold-starts with sharing awareness at minimal waste of memory. With structured container layers and sharing-aware modeling, RainbowCake is robust and tolerant to invocation bursts. We seize the opportunity of container sharing behind the startup process of standard container techniques. RainbowCake breaks the container startup process of a container into three stages and manages different container layers individually. We develop a sharing-aware algorithm that makes event-driven layer-wise caching decisions in real-time. Experiments on OpenWhisk clusters with real-world workloads show that RainbowCake reduces 68% function startup latency and 77% memory waste compared to state-of-the-art solutions.</p>
    </body>
</html>
