<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Excerpt</title>
</head>
<body>
    <h2>Excerpt</h2>
    <p>Diffusion models (DMs) are powerful generative models that demonstrate promising performance across various domains.</p><p>Motivated by their remarkable capability in complex distribution modeling and conditional generation, researchers have developed a series of works applying diffusion models for decision-making tasks in recent years.</p><p>DMs can play various roles in decision-making tasks, such as acting as planners to make better decisions from a long-term perspective, serving as policies to support complex multimodal-distribution modeling, and working as data synthesizers to assist reinforcement learning (RL) training.</p><p>Among these roles, diffusion planning is the most widely applied paradigm.</p><p>Unlike auto-regressive planning in previous model-based RL approaches, diffusion planning avoids severe compounding errors by directly generating the entire trajectory rather than one-step transition.</p><p>Also, its powerful conditional generation capability allows planning at the trajectory level without being limited to step-wise shortsightedness.</p><p>The diffusion planning paradigm has achieved state-of-the-art (SOTA) performance in various offline RL tasks, including single-agent RL, multi-agent RL, meta RL, and more.</p><p>One key issue that diffusion planning faces is the expensive iterative sampling cost.</p><p>The low decision frequency is primarily attributed to modeling a denoising process for a long-horizon trajectory distribution, which requires a heavy neural network backbone and multiple forward passes.</p><p>Experimental results indicate that it is not, for the detailed trajectory information in long-horizon segments is highly redundant.</p><p>Besides, in practice, agents often struggle to reach the planned distant state.</p><p>These facts argue that while long-horizon planning helps improve foresight, it introduces redundant information in distinct parts.</p><p>Ignoring the modeling of these redundant parts in the diffusion planning process will significantly reduce the complexity of the trajectory distribution to be fitted, making it possible to build a fast and lightweight diffusion planning framework.</p><p>Motivated by these insights, we propose to build a plan refinement process (PRP) to speed up diffusion planning.</p><p>First, we perform “rough” planning, where jumpy planning is executed, only considering the states at intervals that are far apart and ignoring other individual states.</p><p>Then, we refine a small portion of the plan, focusing on the steps closer to the current state.</p><p>This approach has three advantages: 1) It reduces the length of the sequences generated by the diffusion model, simplifying the complexity of the probability distribution to be fitted.</p><p>2) It significantly reduces the search space of plans, making it easier for the planner to find well-performed trajectories.</p><p>3) Since only the first action of each step is executed, rough planning of steps further away causes no noticeable performance drop.</p><p>Diffusion planning with PRP, which we call DiffuserLite, is simple, fast, and lightweight.</p><p>Our experiments have demonstrated the effectiveness of PRP, significantly increasing decision-making frequency while achieving SOTA performance.</p><p>Moreover, it can be easily adapted to other existing diffusion planning methods.</p><p>This paradigm relies on multiple forwarding complex neural networks, resulting in extremely low decision-making frequencies (typically 1-10Hz, or even less than 1Hz), severely hindering its real-world deployment.</p><p>Both facts indicate that terms in distant parts of a plan become increasingly redundant, whereas the closer parts are more crucial.</p><p>Specifically, our proposed PRP consists of L planning levels.</p><p>By this design, only the first planned intervals are refined in the next level, and the other redundant details are all ignored, resulting in a coarse-to-fine generation process.</p><p>PRP ensures that long-term planning maintains foresight while alleviating the burden of modeling redundant information.</p><p>The absence of redundant details in PRP allows for a significant reduction in the complexity of the fitted distribution at each level.</p><p>This reduction in complexity enables us to utilize a lighter neural network backbone, shorter network input sequence lengths, and a reduced number of denoising steps.</p><p>Key points generated at former levels often sufficiently reflect the quality of the entire trajectory, which allows the planner to focus more on finding distant key points and planning actions for the immediate steps, reducing search space and complexity.</p><p>Employing PRP results in a new lightweight architecture for diffusion planning, which we refer to as DiffuserLite.</p><p>DiffuserLite can reduce the complexity of the fit distribution and significantly increase the decision-making frequency, achieving 122Hz on average for the need of real-time control.</p><p>We employ DiT as the noise predictor backbone, instead of the more commonly used UNet due to the significantly reduced length of the generated sequences in each level (typically around 5).</p><p>For conditional sampling, we utilize CFG instead of CG, as the slow gradient computation process of CG reduces the frequency of decision-making.</p><p>The Critic C in DiffuserLite plays two important roles: providing generation conditions during the diffusion training process and selecting the optimal plan from the candidates generated by the diffusion model during inference.</p><p>To address this challenge, we introduce an option to use the sum of discounted rewards and the value of the last state as an additional property design.</p><p>After obtaining the optimal trajectory from the last level through critic selection, we utilize an additional inverse dynamic model at = h(ot, ot+1) to extract the action to be executed.</p><p>DiffuserLite aims to achieve real-time diffusion planning to support its application in real-world scenarios.</p><p>Therefore, we introduce Rectified flow for further increasing the decision-making frequency.</p><p>We explored the performance of the DiffuserLite on various tasks on D4RL, Robomimic, and FinRL.</p><p>The runtime cost of DiffuserLite with D, R1, and R2 backbones is only 1.23%, 0.89%, and 0.51% of the average runtime cost of Diffuser and DD, respectively.</p><p>These improvements are attributed to ignoring redundant information in PRP, which reduces the complexity of the distribution that the backbone generative model needs to fit, allowing us to employ a light neural network backbone and use fewer sampling steps to conduct perfect-enough planning.</p><p>DiffuserLite continues to exhibit its superiority in these real-world tasks, achieving performance comparable to SOTA algorithms.</p><p>This illustrates the potential application of DiffuserLite in real-world scenarios.</p><p>AlignDiff-Lite achieves a 560% improvement in decision-making frequency compared to AlignDiff, while only experiencing a small performance drop of 3.2%.</p><p>This result demonstrates the potential of DiffuserLite serving as a plugin to accelerate diffusion planning across various domains.</p><p>The notable performance drop demonstrates the importance of a long-enough planning horizon.</p><p>The large standard deviation and the significant performance drop provide strong evidence for the limitations of one-shot generation planning, having difficulties in modeling the distribution of detailed long-horizon trajectories.</p><p>However, DiffuserLite can maintain high performance with fast decision-making frequency due to its lite architecture and simplified fitted distribution.</p><p>DiffuserLite has more clean plugin design and undoubtedly contributes to increasing decision-making frequency and performance.</p>
    <h2>Original Abstract</h2> 
    <p>Diffusion models have shown great promise in decision-making tasks, particularly in offline reinforcement learning, due to their ability to model complex distributions and generate entire trajectories. However, their high computational cost and low decision-making frequency hinder real-world deployment. To address this, we propose DiffuserLite, a lightweight diffusion planning framework that incorporates a Plan Refinement Process (PRP). PRP begins with rough, interval-based trajectory planning and refines only portions near the current state, reducing sequence length and distribution complexity. This hierarchical, coarse-to-fine strategy enables faster inference, simplified network design, and efficient sampling. DiffuserLite achieves up to 122Hz decision-making frequency, significantly outperforming prior diffusion-based planners in both speed and efficiency, with minimal performance trade-offs. Empirical evaluations on D4RL, Robomimic, and FinRL benchmarks confirm its state-of-the-art competitiveness and real-time applicability. DiffuserLite also demonstrates versatility as a plugin for existing diffusion planners, offering a 560% speed improvement over AlignDiff with only a 3.2% performance drop. These results highlight the potential of PRP-driven lightweight planning in bridging the gap between high-performance trajectory modeling and real-time decision-making.</p>
</body>
</html>
