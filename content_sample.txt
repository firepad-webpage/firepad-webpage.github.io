**Relevant Content for Abstract Preparation**


### Community Preference Optimization (COMPO)


Language models often aggregate diverse and conflicting human feedback, leading to outputs optimized for a hypothetical "average" user. COMPO addresses this by personalizing preference optimization for language models (LMs) using contextual information about the preference provider, focusing on group-level preferences. This is inspired by recommender systems, aiming to generate outputs tailored to specific communities. To this end, the COMPRED dataset was introduced, which comprises community-level preferences extracted from Reddit, enabling personalization without individual privacy risks.


### Dataset: COMPRED


COMPRED includes over 1 million preference pairs across 187 subreddits, grouped into five domains:
1. **Science**: Capturing divergences arising from topic specialization (e.g., /r/science vs. /r/StringTheory).
2. **Finance**: Highlighting distinctions between subreddits focused on varying income brackets and investing goals.
3. **History**: Addressing different norms for responses (e.g., /r/AskHistorians’ academic approach vs. /r/History).
4. **Politics**: Divided by leanings, issues, or regional focus (e.g., /r/Conservative vs. /r/askliberal).
5. **Gender/Sexuality**: Exploring intersections with other demographics and topics such as parenting and fashion.


The dataset uses Reddit’s post-comment structure, relying on upvotes as a proxy for community preferences. Preference pairs are created by comparing responses to identical prompts posted at different times, factoring in upvotes and post timings to avoid biases.


### Motivational Experiment


To demonstrate the value of incorporating subreddit context, reward models were trained with and without community identifiers. Models trained with subreddit context achieved higher preference prediction accuracy, particularly in datasets like politics and gender, where community-specific preferences are pronounced. In contrast, conditioning on the wrong subreddit significantly reduced performance.


### Main Experiments: COMPO


Using Llama-2 7B as the base model, COMPO was evaluated against baselines to assess the impact of contextualizing LMs with community identifiers:
1. **SFT-NC**: Finetuning with no subreddit context.
2. **DPO**: Direct preference optimization without subreddit context.
3. **SFT-C**: Finetuning with subreddit context but no preference tuning.


COMPO consistently outperformed these baselines in both automated and human evaluations, with notable improvements in politically and culturally sensitive domains. Performance degraded when random subreddit identifiers were introduced, underscoring the importance of accurate contextualization.


### Human Evaluation


Human annotators evaluated the relevance of responses from COMPO and baseline models across eight subreddits. COMPO was preferred in 46.5% of cases, significantly outperforming baselines like DPO (37.1%). Annotators noted COMPO’s ability to generate responses aligned with subreddit-specific norms and values, especially in politically diverse and gender-related contexts.


### Analysis


Further analysis revealed that subreddit context was most beneficial when subreddit predictability (via input text) was low, indicating the added value of explicit contextualization. High predictability reduced the advantage of community-specific tuning, suggesting opportunities for efficient resource allocation by routing predictable examples to generalist models.


### Conclusions


COMPO demonstrates the potential of personalized preference optimization for LMs by incorporating community-level context. The approach improves the relevance of model outputs to specific communities and introduces the COMPRED dataset for future research in personalized LMs. This work also highlights directions for addressing challenges like intra-community diversity, cold-start problems, and the risks of reinforcing echo chambers.