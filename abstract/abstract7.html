<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
    <p>The generation and manipulation of 3D meshes are pivotal for applications across entertainment, virtual and augmented reality, and healthcare. However, existing methods struggle to achieve fine-grained, spatially disentangled control of 3D shapes, often relying on Graph Convolutional Network (GCN)-based auto-encoders (AEs) that produce highly entangled latent spaces and face scalability issues with high-resolution meshes. We propose the Locally Adaptive Morphable Model (LAMM), a novel framework that circumvents these limitations by enabling direct, localized mesh manipulation without partitioning the latent code or introducing explicit disentanglement objectives. LAMM employs fully connected layers and a global receptive field to respect the distinct semantics of registered mesh vertices, allowing for both unconditional shape generation and fine-grained editing via direct control inputs. Extensive experiments on 3D human head and hand meshes demonstrate that LAMM achieves state-of-the-art performance in both disentanglement and reconstruction while scaling efficiently to high-resolution data. Our model surpasses existing methods in terms of memory efficiency and inference speed, offering practical benefits such as faster CPU-based execution and reduced resource requirements. LAMM's capabilities democratize access to advanced 3D modeling techniques, enabling applications ranging from detailed facial identity editing to region swapping and geometric sampling.</p>
</body>
</html>
