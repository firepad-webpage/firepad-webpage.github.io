<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
    <p>The rapid advancement of diffusion models has significantly improved content generation across various modalities, yet video generation still lags in visual quality due to noisy pre-training data and the lack of alignment with human preferences. To address these challenges, we introduce InstructVideo, a novel framework that efficiently aligns text-to-video diffusion models with human feedback. Our method reformulates reward fine-tuning as a video editing procedure, reducing computational overhead by leveraging partial inference in the DDIM sampling chain. Additionally, we propose Segmental Video Reward (SegVR) and Temporally Attenuated Reward (TAR) to provide sparse yet effective reward signals, enhancing both temporal consistency and frame-level quality. Extensive experiments demonstrate that InstructVideo surpasses existing reward fine-tuning methods, such as DDPO and DRaFT, delivering videos with clearer structures, better scene coherence, improved video-text alignment, and superior motion fluidity. Notably, these improvements are achieved without sacrificing generalization capabilities, setting a new standard for video generation. Our findings highlight the importance of combining efficient optimization techniques with reward models to advance the alignment of video diffusion models with human preferences.</p>
</body>
</html>
