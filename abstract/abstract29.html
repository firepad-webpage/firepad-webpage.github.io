<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<p>Single-image super-resolution (SISR) is a challenging task due to real-world degradation variability and the ill-posed nature of generating high-resolution images from low-resolution inputs. While diffusion probabilistic models (DPMs) have shown strong generative capabilities in this domain, they suffer from training-sampling discrepancies and inefficiencies in convergence and sampling. This paper introduces DREAM (Diffusion Rectification and Estimation-Adaptive Models), a simple yet effective training framework that addresses these challenges through two key components: diffusion rectification and estimation adaptation. Diffusion rectification aligns training more closely with sampling by incorporating the model’s own predictions, while estimation adaptation blends ground-truth information with self-estimation to balance perceptual quality and distortion. DREAM integrates easily into existing diffusion-based SISR models without altering architecture or sampling procedures. Extensive experiments across various baselines and datasets show that DREAM accelerates convergence by 2–3×, reduces sampling steps by up to 20×, and improves both distortion and perceptual metrics, including in out-of-distribution scenarios. These results demonstrate DREAM’s effectiveness in bridging the training-inference gap and enhancing robustness in high-quality image generation.</p>
</body>
</html>
