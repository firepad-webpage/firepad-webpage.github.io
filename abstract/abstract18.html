<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
    <p>Graph Neural Networks (GNNs) have achieved strong performance in graph-level prediction tasks but remain opaque due to their limited interpretability, hindering adoption in sensitive domains. Existing global explainers often rely on subgraph-level abstractions or instance-level analysis, which fails to capture model-wide decision logic. This work introduces GRAPHTRAIL, a post-hoc, end-to-end global explainer that translates the behavior of a black-box GNN into a human-interpretable boolean formula over learned subgraph concepts. GRAPHTRAIL leverages the computation tree structure induced by message passing in GNNs, reducing the candidate concept space from exponential to linear complexity. It ranks trees using Shapley values and applies symbolic regression to learn interpretable decision rules. Extensive experiments demonstrate that GRAPHTRAIL surpasses existing methods in fidelity, robustness, data efficiency, and interpretability. By aligning explanations with the computational structure of GNNs, GRAPHTRAIL offers a principled approach to understanding and trusting their predictions.</p>
</body>
</html>
